# Distributed-Representations-Made-Easy
Distributed Representations (DR) play a significant role in machine learning. DR is a principled way of representing entities (say, cats or dogs) in terms of vectors.  Entities sharing common properties have  vector representations that are nearer to each other.

The input and output of the Machine Learning (ML) models are often numeric. This requires finding a suitable numeric representation of text. Hence, they are encoded into numeric forms. One such example is One Hot Encoding. However, this kind of encoding does not capture the syntactic and semantic similarity of words in a corpus. This is taken care of by Distributed Representations. The famous Word2Vec model captures these similarities when provided with a corpus. 
